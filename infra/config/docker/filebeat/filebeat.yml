# Filebeat 配置 - 容器日志采集
# 用于采集 Docker 容器日志并发送到 Elasticsearch

filebeat.inputs:
  # 采集所有容器日志
  - type: container
    enabled: true
    paths:
      - /var/lib/docker/containers/*/*.log
    processors:
      # 添加容器元数据（名称、镜像、标签等）
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"
      # 解析 JSON 日志（如果应用输出结构化日志）
      - decode_json_fields:
          fields: ["message"]
          target: "json"
          overwrite_keys: true

# ==================== Elasticsearch 输出配置 ====================
output.elasticsearch:
  # Elasticsearch 地址
  hosts: ["elasticsearch:9200"]

  # 认证信息
  username: "elastic"
  password: "Nexora@2026"

  # 索引配置：使用容器 label 动态命名
  # 有 logging_label 的容器使用专用索引，否则使用默认索引
  indices:
    - index: "%{[container.labels.logging_label]}-logs-%{+yyyy.MM.dd}"
      when:
        contains:
          container.labels.logging_label: ""
    - index: "nexora-logs-%{+yyyy.MM.dd}"

  # 批量处理配置
  bulk_max_size: 50
  flush_interval: 5s

# ==================== Kibana 配置 ====================
setup.kibana:
  host: "http://kibana:5601"
  username: "elastic"
  password: "Nexora@2026"

# 自动创建 Kibana 索引模式和 Dashboard
setup.template.enabled: true
setup.template.name: "nexora-logs"
setup.template.pattern: "nexora-*"
setup.ilm.enabled: false

# ==================== 日志处理管道 ====================
processors:
  # 添加主机信息
  - add_host_metadata:
      when.not.contains.tags: forwarded

  # 添加云提供商信息（如果在云上运行）
  - add_cloud_metadata: ~

  # 添加事件时区
  - add_locale: ~

  # 删除多余的字段
  - drop_fields:
      fields: ["agent.ephemeral_id", "agent.hostname", "agent.id", "agent.version"]
      ignore_missing: true

# ==================== 日志级别配置 ====================
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
