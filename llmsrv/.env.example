# Tiz AI Service Configuration
# Copy this file to .env and fill in your values

# Service Configuration
SERVICE_NAME=llmsrv
SERVICE_PORT=8106
DEBUG=false

# LLM Configuration
# API key for your LLM provider (required)
LLM_API_KEY=your-api-key-here

# API URL (default: OpenAI compatible)
# For OpenAI: https://api.openai.com/v1
# For Azure: https://your-resource.openai.azure.com/openai/deployments/your-deployment
# For other providers: check their documentation
LLM_API_URL=https://api.openai.com/v1

# Model to use
LLM_MODEL=gpt-4o

# Generation parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096

# Timeout settings (in seconds)
LLM_TIMEOUT=60
STREAM_TIMEOUT=120
